# FIVE GUYS - MLM Fine-Tuning in MBTI Task

## Application

<img src="https://github.com/user-attachments/assets/a357ce03-f47b-470d-ae36-1755fd300738" width="800"/>


## MLM with MBTI

<img src="https://github.com/user-attachments/assets/261e6c6e-29ee-4d2d-aa01-63385046c3ae" width="800"/>
<img src="https://github.com/user-attachments/assets/d8043fa7-301c-4c4b-a4d0-051ce0eaf504" width="800"/>
<img src="https://github.com/user-attachments/assets/ca62b09d-2537-4d78-b160-1d0e12650b54" width="800"/>
<img src="https://github.com/user-attachments/assets/a1bccc4b-e625-489b-be8f-ad3783082622" width="800"/>


## Comparison with Vanilla Fine-Tuning

<img src="https://github.com/user-attachments/assets/753c162d-57bd-48c3-9dbf-0d56da1ad863" width="800"/>


## Result

<img src="https://github.com/user-attachments/assets/a5f1ddaf-5559-49f7-85cb-b3e35461e74c" width="800"/>


## Acknowlegement

We acknowledge the significant contribution of [KcELECTRA](https://github.com/Beomi/KcELECTRA) to our project. 
The pre-trained model provided a robust foundation for implementing and fine-tuning our NLP tasks in the Korean language domain.
